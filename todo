make spider chase down other links
    add resricted and allowed domains
when project finish, potential in buying rotating proxy,
create a search algorithim, start of using wikipedia
Start using vpn if scraping ***IMPORTANT**
try out proxy lists
finish webscraper so it keeps going to the subpages and downloading
try on wikipedia
create index for html to display all words and frequency, proportion
#tfdf vector