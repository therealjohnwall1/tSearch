1. when project finish, potential in buying rotating proxy,
2. create a search algorithim, start of using wikipedia
3. store html files using json(link,title, etc)
4. Start using vpn if scraping ***IMPORTANT**
5. try out proxy lists
6. finish webscraper so it keeps going to the subpages and downloading
7. try on wikipedia
8 create index for html to display all words and frequency, proportion
#tfdf vector